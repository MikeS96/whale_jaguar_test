{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant imports\n",
    "\n",
    "# Miscellaneous\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# To encode values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Convert a collection of text documents to a matrix of token counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "\n",
    "# Others\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "The file contains 202,372 records. Each json record contains following attributes:\n",
    "\n",
    "-  `category`: Category article belongs to\n",
    "-  `headline`: Headline of the article \n",
    "-  `authors`: Person authored the article\n",
    "-  `link`: Link to the post\n",
    "-  `short_description`: Short description of the article\n",
    "-  `date`: Date the article was published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Morgan Freeman 'Devastated' That Sexual Harass...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/morgan-fr...</td>\n",
       "      <td>\"It is not right to equate horrific incidents ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Donald Trump Is Lovin' New McDonald's Jingle I...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donald-tr...</td>\n",
       "      <td>It's catchy, all right.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>What To Watch On Amazon Prime That’s New This ...</td>\n",
       "      <td>Todd Van Luling</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/amazon-pr...</td>\n",
       "      <td>There's a great mini-series joining this week.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Mike Myers Reveals He'd 'Like To' Do A Fourth ...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/mike-myer...</td>\n",
       "      <td>Myer's kids may be pushing for a new \"Powers\" ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>What To Watch On Hulu That’s New This Week</td>\n",
       "      <td>Todd Van Luling</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hulu-what...</td>\n",
       "      <td>You're getting a recent Academy Award-winning ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "5  ENTERTAINMENT  Morgan Freeman 'Devastated' That Sexual Harass...   \n",
       "6  ENTERTAINMENT  Donald Trump Is Lovin' New McDonald's Jingle I...   \n",
       "7  ENTERTAINMENT  What To Watch On Amazon Prime That’s New This ...   \n",
       "8  ENTERTAINMENT  Mike Myers Reveals He'd 'Like To' Do A Fourth ...   \n",
       "9  ENTERTAINMENT         What To Watch On Hulu That’s New This Week   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "5       Ron Dicker  https://www.huffingtonpost.com/entry/morgan-fr...   \n",
       "6       Ron Dicker  https://www.huffingtonpost.com/entry/donald-tr...   \n",
       "7  Todd Van Luling  https://www.huffingtonpost.com/entry/amazon-pr...   \n",
       "8    Andy McDonald  https://www.huffingtonpost.com/entry/mike-myer...   \n",
       "9  Todd Van Luling  https://www.huffingtonpost.com/entry/hulu-what...   \n",
       "\n",
       "                                   short_description       date  \n",
       "0  She left her husband. He killed their children... 2018-05-26  \n",
       "1                           Of course it has a song. 2018-05-26  \n",
       "2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26  \n",
       "3  The actor gives Dems an ass-kicking for not fi... 2018-05-26  \n",
       "4  The \"Dietland\" actress said using the bags is ... 2018-05-26  \n",
       "5  \"It is not right to equate horrific incidents ... 2018-05-26  \n",
       "6                            It's catchy, all right. 2018-05-26  \n",
       "7     There's a great mini-series joining this week. 2018-05-26  \n",
       "8  Myer's kids may be pushing for a new \"Powers\" ... 2018-05-26  \n",
       "9  You're getting a recent Academy Award-winning ... 2018-05-26  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_json('dataset/News_Category_Dataset_v2.json', lines=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sherlock/anaconda3/envs/kitty/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>41</td>\n",
       "      <td>199344</td>\n",
       "      <td>27993</td>\n",
       "      <td>200812</td>\n",
       "      <td>178353</td>\n",
       "      <td>2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Sunday Roundup</td>\n",
       "      <td></td>\n",
       "      <td>https://www.huffingtonpost.comhttp://stylelike...</td>\n",
       "      <td></td>\n",
       "      <td>2013-01-17 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>32739</td>\n",
       "      <td>90</td>\n",
       "      <td>36620</td>\n",
       "      <td>2</td>\n",
       "      <td>19712</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category        headline authors  \\\n",
       "count     200853          200853  200853   \n",
       "unique        41          199344   27993   \n",
       "top     POLITICS  Sunday Roundup           \n",
       "freq       32739              90   36620   \n",
       "first        NaN             NaN     NaN   \n",
       "last         NaN             NaN     NaN   \n",
       "\n",
       "                                                     link short_description  \\\n",
       "count                                              200853            200853   \n",
       "unique                                             200812            178353   \n",
       "top     https://www.huffingtonpost.comhttp://stylelike...                     \n",
       "freq                                                    2             19712   \n",
       "first                                                 NaN               NaN   \n",
       "last                                                  NaN               NaN   \n",
       "\n",
       "                       date  \n",
       "count                200853  \n",
       "unique                 2309  \n",
       "top     2013-01-17 00:00:00  \n",
       "freq                    100  \n",
       "first   2012-01-28 00:00:00  \n",
       "last    2018-05-26 00:00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe info of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category             0\n",
       "headline             0\n",
       "authors              0\n",
       "link                 0\n",
       "short_description    0\n",
       "date                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for NaNs\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIME', 'ENTERTAINMENT', 'WORLD NEWS', 'IMPACT', 'POLITICS',\n",
       "       'WEIRD NEWS', 'BLACK VOICES', 'WOMEN', 'COMEDY', 'QUEER VOICES',\n",
       "       'SPORTS', 'BUSINESS', 'TRAVEL', 'MEDIA', 'TECH', 'RELIGION',\n",
       "       'SCIENCE', 'LATINO VOICES', 'EDUCATION', 'COLLEGE', 'PARENTS',\n",
       "       'ARTS & CULTURE', 'STYLE', 'GREEN', 'TASTE', 'HEALTHY LIVING',\n",
       "       'THE WORLDPOST', 'GOOD NEWS', 'WORLDPOST', 'FIFTY', 'ARTS',\n",
       "       'WELLNESS', 'PARENTING', 'HOME & LIVING', 'STYLE & BEAUTY',\n",
       "       'DIVORCE', 'WEDDINGS', 'FOOD & DRINK', 'MONEY', 'ENVIRONMENT',\n",
       "       'CULTURE & ARTS'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List unique values in the df['name'] column\n",
    "df.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's a great mini-series joining this week.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[7][\"short_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27487, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles = df[df['date'] >= pd.Timestamp(2017,5,5)]\n",
    "news_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIME', 'ENTERTAINMENT', 'WORLD NEWS', 'IMPACT', 'POLITICS',\n",
       "       'WEIRD NEWS', 'BLACK VOICES', 'WOMEN', 'COMEDY', 'QUEER VOICES',\n",
       "       'SPORTS', 'BUSINESS', 'TRAVEL', 'MEDIA', 'TECH', 'RELIGION',\n",
       "       'SCIENCE', 'LATINO VOICES', 'EDUCATION', 'COLLEGE', 'PARENTS',\n",
       "       'ARTS & CULTURE', 'STYLE', 'GREEN', 'TASTE', 'HEALTHY LIVING',\n",
       "       'THE WORLDPOST', 'GOOD NEWS'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List unique values in the df['name'] column\n",
    "news_articles.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles after removing duplicates: 26384\n"
     ]
    }
   ],
   "source": [
    "# Filter headlines with less than 5 characters\n",
    "news_articles = news_articles[news_articles['headline'].apply(lambda x: len(x.split())>5)]\n",
    "news_articles.sort_values('headline',inplace=True, ascending=False)\n",
    "duplicated_articles_series = news_articles.duplicated('headline', keep = False)\n",
    "news_articles = news_articles[~duplicated_articles_series]\n",
    "print(\"Total number of articles after removing duplicates:\", news_articles.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles :  26384\n",
      "Total number of authors :  3990\n",
      "Total number of unqiue categories :  28\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of articles : \", news_articles.shape[0])\n",
    "print(\"Total number of authors : \", news_articles[\"authors\"].nunique())\n",
    "print(\"Total number of unqiue categories : \", news_articles[\"category\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Barplot per category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/vikashrajluhaniwal/recommending-news-articles-based-on-read-articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2017-05-31    2198\n",
       "2017-06-30    2474\n",
       "2017-07-31    2329\n",
       "2017-08-31    2434\n",
       "2017-09-30    2171\n",
       "2017-10-31    2248\n",
       "2017-11-30    2111\n",
       "2017-12-31    1934\n",
       "2018-01-31    2065\n",
       "2018-02-28    1694\n",
       "2018-03-31    1778\n",
       "2018-04-30    1580\n",
       "2018-05-31    1368\n",
       "Freq: M, Name: headline, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Articles per month\n",
    "news_articles_per_month = news_articles.resample('m',on = 'date')['headline'].count()\n",
    "news_articles_per_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'such', 'only', \"needn't\", 'here', \"shan't\", \"don't\", 's', 'most', 'these', 'again', 'o', 'under', 'whom', 'each', 'd', 'it', \"you're\", 'm', 'have', 'into', 'very', 'so', 'to', 'were', 'won', 'more', 'now', 'she', 'the', 'until', 'your', 'aren', 'ours', \"weren't\", 'just', 'theirs', \"haven't\", 'ourselves', 'ain', 'herself', 'when', 'own', 'because', 'i', 'shan', \"hasn't\", 'shouldn', 'who', 'below', 'no', 'itself', 't', 'some', 'why', 'with', 'can', \"won't\", 'himself', 'them', 'not', 'against', 'ma', 'didn', 'wasn', 'there', 'he', 'during', 'all', 'don', 'doing', 'mustn', 'after', 'as', 'at', 'from', \"doesn't\", \"shouldn't\", 'had', 'before', 'is', 'being', 'you', 'our', 'few', 'that', 'and', 'will', 'which', 'those', 'if', 'hadn', \"mustn't\", 'having', 'do', 'y', 'doesn', 'other', 'its', 'did', 'mightn', 'yourself', 'between', \"hadn't\", 'a', 'my', \"wouldn't\", 'his', 'what', 'her', 'does', \"she's\", 'but', 'both', 'same', 'too', \"you'd\", \"aren't\", \"didn't\", \"it's\", 'myself', 'any', 'yours', 'they', \"wasn't\", 'out', 'be', 'off', 'isn', 'needn', 'nor', 'me', 'about', 'how', 'hers', 'up', 'wouldn', 'while', 'was', 'has', 'on', 'for', 'down', 'in', 'him', 'haven', 've', 'where', 'then', 'am', \"isn't\", 'are', 'by', 'their', 'of', 'should', 'yourselves', \"you'll\", 'further', 'through', 'themselves', 'or', 'once', \"mightn't\", 'this', \"should've\", \"that'll\", 'been', 'over', 'above', \"couldn't\", \"you've\", 'couldn', 're', 'hasn', 'weren', 'an', 'than', 'we', 'll'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sherlock/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sherlock/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sherlock/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Below libraries are for text processing using NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Below libraries are for feature representation using sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "# remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# List of stopwords to filter\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop_words:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing non alphanumeric character\n",
    "def alpha_num(text):\n",
    "    return re.sub(r'[^A-Za-z0-9 ]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
    "# Lemmatize words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def rem_lemmatizer(text):\n",
    "    final_text = []\n",
    "    string_l = \"\"\n",
    "    for w in word_tokenize(text):\n",
    "        string_l += lemmatizer.lemmatize(w, pos = \"v\") + \" \"\n",
    "    final_text.append(string_l.strip())\n",
    "    return \" \".join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21194</th>\n",
       "      <td>HEALTHY LIVING</td>\n",
       "      <td>“To The Bone” Didn’t Teach Me Glamour. It Taug...</td>\n",
       "      <td>Mycah Hazel, Contributorblogger, equal opportu...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/to-the-bo...</td>\n",
       "      <td>Oftentimes, films or TV shows about eating dis...</td>\n",
       "      <td>2017-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>QUEER VOICES</td>\n",
       "      <td>‘Will &amp; Grace’ Creator To Donate Gay Bunny Boo...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-grac...</td>\n",
       "      <td>It's about to be a lot easier for kids in Mike...</td>\n",
       "      <td>2018-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25186</th>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>‘We Are the Same Blood’: The Invisible Lives O...</td>\n",
       "      <td>Sara Hylton, Women &amp; Girls Hub</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/we-are-th...</td>\n",
       "      <td>A girl from the Dalit village of Harirajpur, i...</td>\n",
       "      <td>2017-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26210</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>‘WannaCry’ Ransomware Attack Raises Alarm Bell...</td>\n",
       "      <td>Stateline, ContributorStateline provides daily...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/wannacry-...</td>\n",
       "      <td>While the recent global cyberattack has spared...</td>\n",
       "      <td>2017-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20973</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>‘Walking Dead’ Reportedly Cancels Comic-Con Pr...</td>\n",
       "      <td>Bill Bradley</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/walking-d...</td>\n",
       "      <td>But the panel will still happen.</td>\n",
       "      <td>2017-07-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                           headline  \\\n",
       "21194  HEALTHY LIVING  “To The Bone” Didn’t Teach Me Glamour. It Taug...   \n",
       "2932     QUEER VOICES  ‘Will & Grace’ Creator To Donate Gay Bunny Boo...   \n",
       "25186      WORLD NEWS  ‘We Are the Same Blood’: The Invisible Lives O...   \n",
       "26210        POLITICS  ‘WannaCry’ Ransomware Attack Raises Alarm Bell...   \n",
       "20973   ENTERTAINMENT  ‘Walking Dead’ Reportedly Cancels Comic-Con Pr...   \n",
       "\n",
       "                                                 authors  \\\n",
       "21194  Mycah Hazel, Contributorblogger, equal opportu...   \n",
       "2932                                       Elyse Wanshel   \n",
       "25186                     Sara Hylton, Women & Girls Hub   \n",
       "26210  Stateline, ContributorStateline provides daily...   \n",
       "20973                                       Bill Bradley   \n",
       "\n",
       "                                                    link  \\\n",
       "21194  https://www.huffingtonpost.com/entry/to-the-bo...   \n",
       "2932   https://www.huffingtonpost.com/entry/will-grac...   \n",
       "25186  https://www.huffingtonpost.com/entry/we-are-th...   \n",
       "26210  https://www.huffingtonpost.com/entry/wannacry-...   \n",
       "20973  https://www.huffingtonpost.com/entry/walking-d...   \n",
       "\n",
       "                                       short_description       date  \n",
       "21194  Oftentimes, films or TV shows about eating dis... 2017-07-18  \n",
       "2932   It's about to be a lot easier for kids in Mike... 2018-04-02  \n",
       "25186  A girl from the Dalit village of Harirajpur, i... 2017-05-31  \n",
       "26210  While the recent global cyberattack has spared... 2017-05-19  \n",
       "20973                   But the panel will still happen. 2017-07-20  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21194</th>\n",
       "      <td>healthy living</td>\n",
       "      <td>to bone didnt teach glamour teach respect</td>\n",
       "      <td>Mycah Hazel, Contributorblogger, equal opportu...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/to-the-bo...</td>\n",
       "      <td>oftentimes film tv show eat disorder try convi...</td>\n",
       "      <td>2017-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>queer voices</td>\n",
       "      <td>will grace creator donate gay bunny book every...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-grac...</td>\n",
       "      <td>lot easier kid mike pences home state read a d...</td>\n",
       "      <td>2018-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25186</th>\n",
       "      <td>world news</td>\n",
       "      <td>we blood invisible live indias dalit women</td>\n",
       "      <td>Sara Hylton, Women &amp; Girls Hub</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/we-are-th...</td>\n",
       "      <td>girl dalit village harirajpur odisha chase kit...</td>\n",
       "      <td>2017-05-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26210</th>\n",
       "      <td>politics</td>\n",
       "      <td>wannacry ransomware attack raise alarm bell ci...</td>\n",
       "      <td>Stateline, ContributorStateline provides daily...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/wannacry-...</td>\n",
       "      <td>recent global cyberattack spar federal governm...</td>\n",
       "      <td>2017-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20973</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>walk dead reportedly cancel comiccon press eve...</td>\n",
       "      <td>Bill Bradley</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/walking-d...</td>\n",
       "      <td>panel still happen</td>\n",
       "      <td>2017-07-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                           headline  \\\n",
       "21194  healthy living          to bone didnt teach glamour teach respect   \n",
       "2932     queer voices  will grace creator donate gay bunny book every...   \n",
       "25186      world news         we blood invisible live indias dalit women   \n",
       "26210        politics  wannacry ransomware attack raise alarm bell ci...   \n",
       "20973   entertainment  walk dead reportedly cancel comiccon press eve...   \n",
       "\n",
       "                                                 authors  \\\n",
       "21194  Mycah Hazel, Contributorblogger, equal opportu...   \n",
       "2932                                       Elyse Wanshel   \n",
       "25186                     Sara Hylton, Women & Girls Hub   \n",
       "26210  Stateline, ContributorStateline provides daily...   \n",
       "20973                                       Bill Bradley   \n",
       "\n",
       "                                                    link  \\\n",
       "21194  https://www.huffingtonpost.com/entry/to-the-bo...   \n",
       "2932   https://www.huffingtonpost.com/entry/will-grac...   \n",
       "25186  https://www.huffingtonpost.com/entry/we-are-th...   \n",
       "26210  https://www.huffingtonpost.com/entry/wannacry-...   \n",
       "20973  https://www.huffingtonpost.com/entry/walking-d...   \n",
       "\n",
       "                                       short_description       date  \n",
       "21194  oftentimes film tv show eat disorder try convi... 2017-07-18  \n",
       "2932   lot easier kid mike pences home state read a d... 2018-04-02  \n",
       "25186  girl dalit village harirajpur odisha chase kit... 2017-05-31  \n",
       "26210  recent global cyberattack spar federal governm... 2017-05-19  \n",
       "20973                                 panel still happen 2017-07-20  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Headlines TODO filter points...\n",
    "news_articles['headline'] = news_articles['headline'].str.lower()\n",
    "news_articles['headline'] = news_articles['headline'].apply(remove_stopwords)\n",
    "news_articles['headline'] = news_articles['headline'].apply(alpha_num)\n",
    "news_articles['headline'] = news_articles['headline'].apply(rem_lemmatizer)\n",
    "# Description\n",
    "news_articles['short_description'] = news_articles['short_description'].str.lower()\n",
    "news_articles['short_description'] = news_articles['short_description'].apply(remove_stopwords)\n",
    "news_articles['short_description'] = news_articles['short_description'].apply(alpha_num)\n",
    "news_articles['short_description'] = news_articles['short_description'].apply(rem_lemmatizer)\n",
    "\n",
    "news_articles['category'] = news_articles['category'].str.lower()\n",
    "#news_articles['category'] = news_articles['category'].apply(lambda x: ''.join(x.split()))\n",
    "\n",
    "news_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['healthy living', 'queer voices', 'world news', 'politics',\n",
       "       'entertainment', 'comedy', 'black voices', 'green', 'impact',\n",
       "       'latino voices', 'business', 'women', 'weird news', 'taste',\n",
       "       'crime', 'media', 'parents', 'travel', 'arts & culture', 'tech',\n",
       "       'style', 'education', 'sports', 'religion', 'science',\n",
       "       'the worldpost', 'college', 'good news'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique new categories\n",
    "news_articles.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump</td>\n",
       "      <td>3411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>say</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donald</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gop</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>house</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>white</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>us</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>new</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>health</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bill</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  frequency\n",
       "0   trump       3411\n",
       "1     say        640\n",
       "2  donald        620\n",
       "3     gop        478\n",
       "4   house        441\n",
       "5   white        384\n",
       "6      us        365\n",
       "7     new        344\n",
       "8  health        325\n",
       "9    bill        311"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent unigrams of news belongs 'SCIENCE' category\n",
    "def category_ngram(category, n):\n",
    "    \n",
    "    temp_df = news_articles[news_articles['category'] == category]\n",
    "    \n",
    "    word_vectorizer = CountVectorizer(ngram_range=(n, n), analyzer='word')\n",
    "    sparse_matrix = word_vectorizer.fit_transform(temp_df['headline'])\n",
    "    \n",
    "    frequencies = sum(sparse_matrix).toarray()[0]\n",
    "    \n",
    "    return pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\\\n",
    "            .sort_values(by='frequency', ascending=False) \\\n",
    "            .reset_index() \\\n",
    "            .head(10)\n",
    "\n",
    "category_ngram('politics', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy living</td>\n",
       "      <td>oftentimes film tv show eat disorder try convi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>queer voices</td>\n",
       "      <td>lot easier kid mike pences home state read a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>world news</td>\n",
       "      <td>girl dalit village harirajpur odisha chase kit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politics</td>\n",
       "      <td>recent global cyberattack spar federal governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>panel still happen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                  short_description\n",
       "0  healthy living  oftentimes film tv show eat disorder try convi...\n",
       "1    queer voices  lot easier kid mike pences home state read a d...\n",
       "2      world news  girl dalit village harirajpur odisha chase kit...\n",
       "3        politics  recent global cyberattack spar federal governm...\n",
       "4   entertainment                                 panel still happen"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset indexes\n",
    "news_articles = news_articles.reset_index(drop=True)\n",
    "# Drop unwanted columns\n",
    "news_articles.drop('authors', inplace=True, axis=1)\n",
    "news_articles.drop('link', inplace=True, axis=1)\n",
    "news_articles.drop('date', inplace=True, axis=1)\n",
    "news_articles.drop('headline', inplace=True, axis=1)\n",
    "news_articles.head()\n",
    "# Encoding output\n",
    "#labels_encoded = pd.get_dummies(news_articles.category, prefix='category')\n",
    "#concatenated_dataframes = pd.concat([news_articles, labels_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation set \\\n",
    "# https://towardsdatascience.com/how-to-use-torchtext-for-neural-machine-translation-plus-hack-to-make-it-5x-faster-77f3884d95\n",
    "train, val = train_test_split(news_articles, test_size = 0.2)\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "val.to_csv(\"val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sherlock/anaconda3/envs/kitty/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/sherlock/anaconda3/envs/kitty/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "import spacy\n",
    "import torchtext\n",
    "from torchtext.data import Field, LabelField, BucketIterator, TabularDataset, Iterator\n",
    "en = spacy.load('en')\n",
    "\n",
    "def tokenize_en(sentence):\n",
    "    return [tok.text for tok in en.tokenizer(sentence)]\n",
    "\n",
    "TEXT = Field(tokenize = tokenize_en, batch_first = False)\n",
    "LABEL = LabelField(dtype = torch.long, batch_first = False)\n",
    "#LABEL = Field(sequential=False, use_vocab=False, lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sherlock/anaconda3/envs/kitty/lib/python3.7/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/home/sherlock/anaconda3/envs/kitty/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# associate the text in the 'English' column with the EN_TEXT field,\n",
    "# and 'French' with FR_TEXT , ('category', LABEL)\n",
    "#data_fields = [('category', LABEL), ('headline', TEXT), ('short_description', TEXT)]\n",
    "data_fields = [('c', LABEL), ('s', TEXT)]\n",
    "\n",
    "train, val = TabularDataset.splits(path='./', train='train.csv', validation='val.csv',\n",
    "                                       format='csv', skip_header=True, fields = data_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['c', 's'])\n",
      "dict_values(['world news', ['second', 'group', 'refugees', 'arrive', 'trump', 'call', 'dumb', 'deal']])\n"
     ]
    }
   ],
   "source": [
    "print(train[0].__dict__.keys())\n",
    "print(train[0].__dict__.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'politics'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[10].c[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': 'politics',\n",
       " 's': ['nobody', 'put', 'hillary', 'corner', 'kamala', 'maxine', 'elizabeth']}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the mapping\n",
    "TEXT.build_vocab(train, min_freq = 10, vectors = \"glove.6B.100d\") # max_size=10000\n",
    "LABEL.build_vocab(train, min_freq = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553\n",
      "[('say', 2501), ('trump', 1535), ('president', 946), ('i', 917), ('people', 873), ('new', 835), ('one', 817), ('nt', 809), ('us', 787), ('make', 775), ('get', 726), ('s', 659), ('state', 642), ('time', 640), ('go', 603), ('like', 602), ('take', 574), ('would', 551), ('come', 504), ('know', 488)]\n",
      "0\n",
      "[('politics', 7376), ('entertainment', 2936), ('world news', 1696), ('queer voices', 1101), ('comedy', 859), ('black voices', 780), ('healthy living', 732), ('parents', 631), ('media', 583), ('women', 565), ('sports', 480), ('weird news', 374), ('crime', 316), ('style', 315), ('green', 312), ('taste', 275), ('business', 255), ('impact', 236), ('latino voices', 224), ('religion', 201), ('travel', 167), ('the worldpost', 165), ('arts & culture', 164), ('education', 140), ('tech', 105), ('science', 79), ('college', 33), ('good news', 7)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.stoi['thank'])\n",
    "print(TEXT.vocab.freqs.most_common(20))\n",
    "print(LABEL.vocab.stoi['politics'])\n",
    "print(LABEL.vocab.freqs.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'politics': 0, 'entertainment': 1, 'world news': 2, 'queer voices': 3, 'comedy': 4, 'black voices': 5, 'healthy living': 6, 'parents': 7, 'media': 8, 'women': 9, 'sports': 10, 'weird news': 11, 'crime': 12, 'style': 13, 'green': 14, 'taste': 15, 'business': 16, 'impact': 17, 'latino voices': 18, 'religion': 19, 'travel': 20, 'the worldpost': 21, 'arts & culture': 22, 'education': 23, 'tech': 24, 'science': 25, 'college': 26, 'good news': 27})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sherlock/anaconda3/envs/kitty/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Iterator\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#train_iter = BucketIterator(train, batch_size = 20, sort_key= lambda x: len(x.short_description), shuffle=True)\n",
    "batch_size = 32\n",
    "train_iter, val_iter = BucketIterator.splits(\n",
    " (train, val), # we pass in the datasets we want the iterator to draw data from\n",
    " batch_size = batch_size,\n",
    " device = device, # if you want to use the GPU, specify the GPU number here\n",
    " sort_key=lambda x: len(x.s), # the BucketIterator needs to be told what function it should use to group the data.\n",
    " sort_within_batch=False\n",
    " #repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  1,  0,  0,  5, 10,  2,  0,  0, 15,  3,  3,  0, 11,  0,  0,\n",
      "         0,  0, 21,  6, 14,  2,  9,  0,  1, 19,  0,  1,  4,  6],\n",
      "       device='cuda:0')\n",
      "tensor([[ 600, 2987,    0, 2620,   22, 2585,  106,    0,  268,  107,  564,  296,\n",
      "          264,    0,    8,   25, 1030, 1064,   12,    0, 2488,  371,  297,  678,\n",
      "          549,   10,  951,    5,    3,    0, 1342, 1558],\n",
      "        [ 737,    0,   32,   29,   16,  734,  962,  175,  915,  756,  933,  325,\n",
      "            0,    8,  247, 1065,    0, 1545, 3007,   52,  323, 1645,   15,  547,\n",
      "         1014,  266,  326,   17,   96,  528,   35,   96],\n",
      "        [ 740,    0,    0,   70,  507,    0, 1740,  217,  175,  327, 2927, 3033,\n",
      "          299, 2093,  619,   11, 2147,  336,  625, 2122,   59,  164,    0, 2047,\n",
      "         1279, 2191,   42,   35,   11,    0,    0, 1380],\n",
      "        [ 236, 1819,    0,   90,   38,   11,  182, 2432,   16,   52,    0, 1965,\n",
      "            0,  117,   20,  105,   39, 1038, 2146, 1186,   84,    1,    1,  398,\n",
      "         2464, 2104,   86,  135, 2865,   37,  349,  300],\n",
      "        [2991, 3011,  423,  363,  197,  234, 2386, 1589, 1117,  359,    0, 1328,\n",
      "          600,    0,  149,  112,  933,    8,    0,  771,    0,    1,    1, 1867,\n",
      "            7,    0,  244,  127, 1288,    4,    1,    1],\n",
      "        [2306,    0,  310, 1367,  514, 1080,    1,  224,   42,    1,    0,    1,\n",
      "          989,  744,   54,  218,  124,  636,  838,  792,  679,    1,    1,    1,\n",
      "            0,   18,    1,   55,  825,   26,    1,    1],\n",
      "        [1463,    1,    7,    0,   11,  482,    1,    0,  628,    1, 2316,    1,\n",
      "           74, 2151, 1035,   30,  121,  365,   15,  591, 1221,    1,    1,    1,\n",
      "         1096,  565,    1,  102,    1, 1477,    1,    1],\n",
      "        [ 143,    1,    0, 1847,    0,  412,    1,    0, 1220,    1,    3,    1,\n",
      "           13,    1, 2722,    1,    0, 2028,    1,   74,    0,    1,    1,    1,\n",
      "          465,  381,    1,    0,    1, 1805,    1,    1],\n",
      "        [ 362,    1,  289,    1,    0,  323,    1,   15,    1,    1,   12,    1,\n",
      "            0,    1,   99,    1,    0,  170,    1,   13,    0,    1,    1,    1,\n",
      "           36,    0,    1,    0,    1,    1,    1,    1],\n",
      "        [1195,    1,   78,    1,    0,    8,    1, 1102,    1,    1,  114,    1,\n",
      "            1,    1,   15,    1,  314,  436,    1,  133,  605,    1,    1,    1,\n",
      "         1320,  325,    1,    2,    1,    1,    1,    1],\n",
      "        [2619,    1,   14,    1,  393,   99,    1,    0,    1,    1,  206,    1,\n",
      "            1,    1,    1,    1,    1, 1641,    1,  484,  143,    1,    1,    1,\n",
      "            1, 1087,    1,    0,    1,    1,    1,    1],\n",
      "        [ 630,    1,    1,    1,   22,   40,    1,    0,    1,    1, 1834,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    0,    0,    1,    1,    1,\n",
      "            1, 2057,    1,    0,    1,    1,    1,    1],\n",
      "        [ 296,    1,    1,    1, 1701,  369,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,  916,    1,    1,    1,    1,    1,    1],\n",
      "        [1871,    1,    1,    1,   57,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [ 363,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]], device='cuda:0')\n",
      "torch.Size([32])\n",
      "torch.Size([15, 32])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch.c)\n",
    "    #print(batch.headline)\n",
    "    print(batch.s)\n",
    "    print(batch.c.shape)\n",
    "    #print(batch.headline.shape)\n",
    "    print(batch.s.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n",
      "tensor([ 1,  3,  0,  0,  1, 15,  2,  1,  7,  0,  1,  1,  4,  1, 10,  1,  8,  3,\n",
      "         0,  0,  1,  0,  0, 13, 13,  8,  1,  0, 25, 13,  1, 11],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "#batch = next(iter(val_iter))\n",
    "print(batch.c.shape)\n",
    "print(batch.c.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping the iterator\n",
    "class BatchWrapper:\n",
    "      def __init__(self, dl, x_var, y_vars):\n",
    "            self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x \n",
    "\n",
    "      def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                  x_1 = getattr(batch, self.x_var[0]) # we assume only one input in this wrapper\n",
    "                  x_2 = getattr(batch, self.x_var[1]) # we assume only one input in this wrapper\n",
    "                  #print(x_1.shape)\n",
    "                  #print(x_2.shape)\n",
    "                  x = torch.cat((x_1, x_2), 0) # Concatenating variables\n",
    "                  y = getattr(batch, self.y_vars) # Concatenating variables\n",
    "\n",
    "                  yield (x, y)\n",
    "\n",
    "      def __len__(self):\n",
    "            return len(self.dl)\n",
    "\n",
    "train_dl = BatchWrapper(train_iter, [\"headline\", \"short_description\"], \"category\")\n",
    "valid_dl = BatchWrapper(val_iter, [\"headline\", \"short_description\"], \"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Batch' object has no attribute 'headline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3fc50411b029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-b91766698ea8>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                   \u001b[0mx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we assume only one input in this wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                   \u001b[0mx_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we assume only one input in this wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                   \u001b[0;31m#print(x_1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'headline'"
     ]
    }
   ],
   "source": [
    "print(next(train_dl.__iter__()))\n",
    "print(next(valid_dl.__iter__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "3035\n"
     ]
    }
   ],
   "source": [
    "# Vocab size\n",
    "print(len(LABEL.vocab))\n",
    "print(len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,488,972 trainable parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleLSTMBaseline(\n",
       "  (embedding): Embedding(3035, 400)\n",
       "  (lstm): LSTM(400, 128, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class SimpleLSTMBaseline(nn.Module):\n",
    "    def __init__(self, emb_dim = 400, hidden_dim = 264, layers = 2, drop_prob = 0.5):\n",
    "        super(SimpleLSTMBaseline, self).__init__() # don't forget to call this!\n",
    "        # Input\n",
    "        self.input_size = len(TEXT.vocab)\n",
    "        # Classifier\n",
    "        self.output_size = len(LABEL.vocab)\n",
    "        # Stacked LSTM\n",
    "        self.n_layers = layers\n",
    "        # Hidden units\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Embedding dim\n",
    "        self.embedding_dim = emb_dim\n",
    "        self.train_gpu = torch.cuda.is_available()\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, hidden_dim, num_layers = self.n_layers, dropout = drop_prob)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, self.output_size)\n",
    "        # Activation function\n",
    "        #self.smax =  nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \n",
    "        batch_size = x.size(1)\n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        # Remove sequence dimension\n",
    "        #print('before',lstm_out.shape)\n",
    "        lstm_out = lstm_out[-1, :, :]\n",
    "        #print('after',lstm_out.shape)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        soft_out = self.fc(out)\n",
    "        # Softmax function\n",
    "        #soft_out =F.log_softmax(out, dim = 1)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        #sig_out = sig_out.view(batch_size, -1)\n",
    "        #sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        # reshape to be batch_size first\n",
    "        #print('before soft', soft_out.shape)\n",
    "        #soft_out = soft_out.view(-1, batch_size)\n",
    "        #print('before soft', soft_out.shape)\n",
    "        #soft_out = soft_out[-1, :] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return soft_out, hidden\n",
    "\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        if (self.train_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "embedding_dim = 400\n",
    "hidden_dim = 128\n",
    "hidden_layers = 1\n",
    "dropout_prob = 0.5\n",
    "model = SimpleLSTMBaseline(emb_dim = embedding_dim, hidden_dim = hidden_dim, \n",
    "                             layers = hidden_layers, drop_prob = dropout_prob)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "#Initialize the pretrained embedding\n",
    "#pretrained_embeddings = TEXT.vocab.vectors\n",
    "#model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class SimpleLSTMBaseline(nn.Module):\n",
    "    def __init__(self, emb_dim = 400, hidden_dim = 264, layers = 2, drop_prob = 0.5):\n",
    "        super(SimpleLSTMBaseline, self).__init__() # don't forget to call this!\n",
    "        # Input\n",
    "        self.input_size = len(TEXT.vocab)\n",
    "        # Classifier\n",
    "        self.output_size = len(LABEL.vocab)\n",
    "        # Stacked LSTM\n",
    "        self.n_layers = layers\n",
    "        # Hidden units\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Embedding dim\n",
    "        self.embedding_dim = emb_dim\n",
    "        self.train_gpu = torch.cuda.is_available()\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.embedding_dim)\n",
    "        #self.lstm = nn.LSTM(self.embedding_dim, hidden_dim, num_layers = self.n_layers, dropout = drop_prob,\n",
    "        #                   batch_first = True)\n",
    "        self.fc1 = nn.Linear(self.embedding_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, hidden_dim)\n",
    "        #self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, self.output_size)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # Activation function\n",
    "        #self.smax =  nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        #print('Batch size', batch_size)\n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        x = self.embedding(x)\n",
    "        #print('Embedding', x.shape)\n",
    "        #lstm_out, (hidden, cell) = self.lstm(x)\n",
    "        # remove sequence\n",
    "        #x = torch.squeeze(x, 1)\n",
    "        x = x[:, -1, :]\n",
    "        #print('Removing sequence', x.shape)\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add output layer\n",
    "        #hidden = torch.cat((hidden[-2,:,:],hidden[-1,:,:]), dim = 1)\n",
    "        #print('concat hidden', hidden)\n",
    "        x = self.fc(x)\n",
    "        #print('Final output', x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "def count_parameters(model: nn.Module):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_dim = 264\n",
    "hidden_layers = 1\n",
    "dropout_prob = 0.5\n",
    "model = SimpleLSTMBaseline(emb_dim = embedding_dim, hidden_dim = hidden_dim, \n",
    "                             layers = hidden_layers, drop_prob = dropout_prob)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "#Initialize the pretrained embedding\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10... Step: 100... Loss: 2.340255... Val Loss: 2.616587\n",
      "Epoch: 2/10... Step: 200... Loss: 2.891931... Val Loss: 2.624966\n",
      "Epoch: 2/10... Step: 300... Loss: 2.910921... Val Loss: 2.604806\n",
      "Epoch: 2/10... Step: 400... Loss: 2.501232... Val Loss: 2.662229\n",
      "Epoch: 2/10... Step: 500... Loss: 2.530216... Val Loss: 2.740890\n",
      "Epoch: 2/10... Step: 600... Loss: 2.602314... Val Loss: 2.754738\n",
      "Epoch: 3/10... Step: 700... Loss: 2.264573... Val Loss: 2.760938\n",
      "Epoch: 3/10... Step: 800... Loss: 2.853158... Val Loss: 2.859050\n",
      "Epoch: 3/10... Step: 900... Loss: 2.428112... Val Loss: 2.790881\n",
      "Epoch: 3/10... Step: 1000... Loss: 2.660060... Val Loss: 2.685615\n",
      "Epoch: 3/10... Step: 1100... Loss: 2.315199... Val Loss: 2.705386\n",
      "Epoch: 3/10... Step: 1200... Loss: 2.331552... Val Loss: 2.680952\n",
      "Epoch: 3/10... Step: 1300... Loss: 2.574005... Val Loss: 2.731640\n",
      "Epoch: 4/10... Step: 1400... Loss: 2.124772... Val Loss: 2.747995\n",
      "Epoch: 4/10... Step: 1500... Loss: 2.668533... Val Loss: 2.715187\n",
      "Epoch: 4/10... Step: 1600... Loss: 2.405802... Val Loss: 2.785523\n",
      "Epoch: 4/10... Step: 1700... Loss: 2.591409... Val Loss: 2.797996\n",
      "Epoch: 4/10... Step: 1800... Loss: 2.802400... Val Loss: 2.724091\n",
      "Epoch: 4/10... Step: 1900... Loss: 2.378584... Val Loss: 2.720065\n",
      "Epoch: 5/10... Step: 2000... Loss: 2.891623... Val Loss: 2.770743\n",
      "Epoch: 5/10... Step: 2100... Loss: 2.398223... Val Loss: 2.722483\n",
      "Epoch: 5/10... Step: 2200... Loss: 2.756960... Val Loss: 2.712715\n",
      "Epoch: 5/10... Step: 2300... Loss: 2.281804... Val Loss: 2.764300\n",
      "Epoch: 5/10... Step: 2400... Loss: 2.073114... Val Loss: 2.844893\n",
      "Epoch: 5/10... Step: 2500... Loss: 2.336774... Val Loss: 2.764331\n",
      "Epoch: 5/10... Step: 2600... Loss: 2.320167... Val Loss: 2.738897\n",
      "Epoch: 6/10... Step: 2700... Loss: 2.445530... Val Loss: 2.779915\n",
      "Epoch: 6/10... Step: 2800... Loss: 2.291881... Val Loss: 2.812869\n",
      "Epoch: 6/10... Step: 2900... Loss: 2.324576... Val Loss: 2.831699\n",
      "Epoch: 6/10... Step: 3000... Loss: 2.759033... Val Loss: 2.788804\n",
      "Epoch: 6/10... Step: 3100... Loss: 2.507807... Val Loss: 2.818278\n",
      "Epoch: 6/10... Step: 3200... Loss: 2.638687... Val Loss: 2.850495\n",
      "Epoch: 7/10... Step: 3300... Loss: 2.847998... Val Loss: 2.785629\n",
      "Epoch: 7/10... Step: 3400... Loss: 2.446231... Val Loss: 2.833595\n",
      "Epoch: 7/10... Step: 3500... Loss: 2.751444... Val Loss: 2.792017\n",
      "Epoch: 7/10... Step: 3600... Loss: 2.287723... Val Loss: 2.855013\n",
      "Epoch: 7/10... Step: 3700... Loss: 2.381171... Val Loss: 2.829695\n",
      "Epoch: 7/10... Step: 3800... Loss: 2.046047... Val Loss: 2.833097\n",
      "Epoch: 7/10... Step: 3900... Loss: 2.102132... Val Loss: 2.833186\n",
      "Epoch: 8/10... Step: 4000... Loss: 2.296000... Val Loss: 2.827167\n",
      "Epoch: 8/10... Step: 4100... Loss: 2.791187... Val Loss: 2.813058\n",
      "Epoch: 8/10... Step: 4200... Loss: 2.604145... Val Loss: 2.843642\n",
      "Epoch: 8/10... Step: 4300... Loss: 2.369591... Val Loss: 2.794613\n",
      "Epoch: 8/10... Step: 4400... Loss: 2.546364... Val Loss: 2.780463\n",
      "Epoch: 8/10... Step: 4500... Loss: 2.712769... Val Loss: 2.788079\n",
      "Epoch: 8/10... Step: 4600... Loss: 2.590107... Val Loss: 2.798019\n",
      "Epoch: 9/10... Step: 4700... Loss: 2.114882... Val Loss: 2.791088\n",
      "Epoch: 9/10... Step: 4800... Loss: 2.126750... Val Loss: 2.817267\n",
      "Epoch: 9/10... Step: 4900... Loss: 2.180093... Val Loss: 2.841629\n",
      "Epoch: 9/10... Step: 5000... Loss: 2.023197... Val Loss: 2.840045\n",
      "Epoch: 9/10... Step: 5100... Loss: 2.464267... Val Loss: 2.797268\n",
      "Epoch: 9/10... Step: 5200... Loss: 2.247323... Val Loss: 2.809538\n",
      "Epoch: 10/10... Step: 5300... Loss: 2.787160... Val Loss: 2.856649\n",
      "Epoch: 10/10... Step: 5400... Loss: 2.641449... Val Loss: 2.835684\n",
      "Epoch: 10/10... Step: 5500... Loss: 1.946512... Val Loss: 2.840186\n",
      "Epoch: 10/10... Step: 5600... Loss: 2.609352... Val Loss: 2.878841\n",
      "Epoch: 10/10... Step: 5700... Loss: 2.504575... Val Loss: 2.944664\n",
      "Epoch: 10/10... Step: 5800... Loss: 2.658745... Val Loss: 2.884959\n",
      "Epoch: 10/10... Step: 5900... Loss: 2.042600... Val Loss: 2.913898\n",
      "Epoch: 11/10... Step: 6000... Loss: 1.957651... Val Loss: 2.882863\n",
      "Epoch: 11/10... Step: 6100... Loss: 2.405814... Val Loss: 2.922999\n",
      "Epoch: 11/10... Step: 6200... Loss: 2.331641... Val Loss: 2.855710\n",
      "Epoch: 11/10... Step: 6300... Loss: 2.189302... Val Loss: 2.905891\n",
      "Epoch: 11/10... Step: 6400... Loss: 2.300031... Val Loss: 2.919218\n",
      "Epoch: 11/10... Step: 6500... Loss: 2.613142... Val Loss: 2.933626\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "\n",
    "clip = 5 # gradient clipping\n",
    "epochs = 10\n",
    "model.train() # turn on training mode\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # initialize hidden state\n",
    "    h = model.init_hidden(batch_size)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for batch in train_iter:\n",
    "        y = batch.c\n",
    "        #x1 = batch.headline\n",
    "        x = batch.s\n",
    "        #x = torch.cat((x1, x2), 0) # Concatenating variables\n",
    "        if x.shape[1] != batch_size:\n",
    "            continue\n",
    "        counter += 1\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        opt.zero_grad()\n",
    "        #model.zero_grad()\n",
    "        # get the output from the model\n",
    "        output, h = model(x, h)\n",
    "        \n",
    "        # calculate the loss and perform backprop\n",
    "        loss = loss_func(output, Variable(y))\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        opt.step()\n",
    "        \n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for batch in val_iter:\n",
    "                labels = batch.c\n",
    "                #x1 = batch.headline\n",
    "                inputs = batch.s\n",
    "                if inputs.shape[1] != batch_size:\n",
    "                    continue\n",
    "                \n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                output, val_h = model(inputs, val_h)\n",
    "                val_loss = loss_func(output.view(batch_size, -1), labels.view(batch_size, -1).squeeze())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(epoch + 1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not come here yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# container for sentences\n",
    "headline_arr = np.array([headline for headline in news_articles['headline']])\n",
    "description_arr = np.array([headline for headline in news_articles['short_description']])\n",
    "# Stack features\n",
    "features = np.vstack((headline_arr, description_arr)).T\n",
    "# container for labels\n",
    "labels = np.array([label for label in news_articles['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8485, 2)\n",
      "(8485,)\n",
      "['will grace creator donate gay bunny book every grade school indiana'\n",
      " 'lot easier kid mike pences home state read a day life marlon bundo']\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)\n",
    "print(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARTS & CULTURE' 'BLACK VOICES' 'BUSINESS' 'COLLEGE' 'COMEDY' 'CRIME'\n",
      " 'EDUCATION' 'ENTERTAINMENT' 'GREEN' 'HEALTHY LIVING' 'IMPACT'\n",
      " 'LATINO VOICES' 'MEDIA' 'PARENTS' 'POLITICS' 'QUEER VOICES' 'RELIGION'\n",
      " 'SCIENCE' 'SPORTS' 'STYLE' 'TASTE' 'TECH' 'TRAVEL' 'WEIRD NEWS' 'WOMEN'\n",
      " 'WORLD NEWS']\n",
      "[15 15 15 ...  4  7 14]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Enconde labels as 0, 1, 2..\n",
    "\n",
    "# Label encoding news category\n",
    "enc = LabelEncoder()\n",
    "enc.fit(labels)\n",
    "print(enc.classes_)\n",
    "labels = enc.transform(labels)\n",
    "# enc.inverse_transform([0, 0, 1, 2])\n",
    "print(labels)\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n",
      "[  13  406   85    1  443  170   31 1699   28   15   73   83  290   32\n",
      " 3042  451   63   40  364   34    9   53   72  205  226  557]\n"
     ]
    }
   ],
   "source": [
    "# count unique elements\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 3 and remove it to avoid errors\n",
    "idx = np.where(labels == 3)\n",
    "features = np.delete(features, idx, axis=0)\n",
    "labels = np.delete(labels, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25]\n",
      "[  13  406   85  443  170   31 1699   28   15   73   83  290   32 3042\n",
      "  451   63   40  364   34    9   53   72  205  226  557]\n",
      "(8484, 2)\n",
      "(8484,)\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_labels = OneHotEncoder().fit(labels.reshape(-1,1))\n",
    "print(one_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
